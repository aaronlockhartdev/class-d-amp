//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35813241
// Cuda compilation tools, release 12.9, V12.9.41
// Based on NVVM 7.0.1
//

.version 8.8
.target sm_86
.address_size 64

	// .globl	polynomial_algorithmic_progression
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std3__48__detail44__construct_psa_from_dynamic_exts_values_tagE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std3__48__detail40__construct_psa_from_all_exts_values_tagE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std3__45__cpo5beginE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std3__45__cpo3endE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std3__45__cpo6cbeginE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std3__45__cpo4cendE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std3__45__cpo6rbeginE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std3__45__cpo4rendE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std3__45__cpo7crbeginE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std3__45__cpo5crendE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std3__445_GLOBAL__N__e250edd6_12_freq_resp_cu_c0ad21c66ignoreE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std3__419piecewise_constructE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std3__48in_placeE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std3__420unreachable_sentinelE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std3__47nulloptE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std3__48unexpectE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std6ranges3__45__cpo4swapE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std6ranges3__45__cpo9iter_moveE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std6ranges3__45__cpo7advanceE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std6ranges3__45__cpo5beginE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std6ranges3__45__cpo3endE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std6ranges3__45__cpo6cbeginE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std6ranges3__45__cpo4cendE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std6ranges3__45__cpo9iter_swapE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std6ranges3__45__cpo4nextE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std6ranges3__45__cpo4prevE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std6ranges3__45__cpo4dataE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std6ranges3__45__cpo5cdataE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std6ranges3__45__cpo4sizeE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std6ranges3__45__cpo5ssizeE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c64cuda3std6ranges3__45__cpo8distanceE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c66thrust23THRUST_200802_SM_860_NS6system6detail10sequential3seqE[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c66thrust23THRUST_200802_SM_860_NS12placeholders2_1E[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c66thrust23THRUST_200802_SM_860_NS12placeholders2_2E[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c66thrust23THRUST_200802_SM_860_NS12placeholders2_3E[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c66thrust23THRUST_200802_SM_860_NS12placeholders2_4E[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c66thrust23THRUST_200802_SM_860_NS12placeholders2_5E[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c66thrust23THRUST_200802_SM_860_NS12placeholders2_6E[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c66thrust23THRUST_200802_SM_860_NS12placeholders2_7E[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c66thrust23THRUST_200802_SM_860_NS12placeholders2_8E[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c66thrust23THRUST_200802_SM_860_NS12placeholders2_9E[1];
.global .align 1 .b8 _ZN43_INTERNAL_e250edd6_12_freq_resp_cu_c0ad21c66thrust23THRUST_200802_SM_860_NS12placeholders3_10E[1];

.visible .entry polynomial_algorithmic_progression(
	.param .u64 polynomial_algorithmic_progression_param_0,
	.param .u32 polynomial_algorithmic_progression_param_1,
	.param .f32 polynomial_algorithmic_progression_param_2,
	.param .u64 polynomial_algorithmic_progression_param_3,
	.param .u64 polynomial_algorithmic_progression_param_4,
	.param .u32 polynomial_algorithmic_progression_param_5
)
{
	.reg .pred 	%p<183>;
	.reg .b16 	%rs<19>;
	.reg .f32 	%f<337>;
	.reg .b32 	%r<272>;
	.reg .b64 	%rd<22>;


	ld.param.u64 	%rd7, [polynomial_algorithmic_progression_param_0];
	ld.param.u32 	%r104, [polynomial_algorithmic_progression_param_1];
	ld.param.f32 	%f156, [polynomial_algorithmic_progression_param_2];
	ld.param.u64 	%rd8, [polynomial_algorithmic_progression_param_3];
	ld.param.u64 	%rd9, [polynomial_algorithmic_progression_param_4];
	ld.param.u32 	%r101, [polynomial_algorithmic_progression_param_5];
	cvta.to.global.u64 	%rd1, %rd7;
	// begin inline asm
	activemask.b32 %r102;
	// end inline asm
	// begin inline asm
	mov.u32 %r103, %lanemask_lt;
	// end inline asm
	and.b32  	%r2, %r103, %r102;
	popc.b32 	%r3, %r2;
	setp.lt.u32 	%p6, %r3, %r104;
	selp.b32 	%r4, 0, %r104, %p6;
	selp.b32 	%r5, %r104, 32, %p6;
	selp.b64 	%rd10, %rd8, %rd9, %p6;
	cvta.to.global.u64 	%rd2, %rd10;
	sub.s32 	%r6, %r3, %r4;
	cvt.rn.f32.u32 	%f157, %r6;
	mul.f32 	%f1, %f157, %f156;
	mul.wide.u32 	%rd11, %r4, 4;
	add.s64 	%rd12, %rd1, %rd11;
	ld.global.f32 	%f304, [%rd12];
	add.s32 	%r241, %r4, 1;
	setp.ge.u32 	%p7, %r241, %r5;
	mov.f32 	%f303, 0f00000000;
	@%p7 bra 	$L__BB0_43;

	mov.f32 	%f280, 0f00000000;
	copysign.f32 	%f3, %f1, %f280;
	not.b32 	%r106, %r4;
	add.s32 	%r107, %r5, %r106;
	and.b32  	%r108, %r107, 1;
	setp.eq.b32 	%p8, %r108, 1;
	mov.pred 	%p9, 0;
	xor.pred  	%p10, %p8, %p9;
	not.pred 	%p11, %p10;
	mov.f32 	%f281, %f1;
	mov.f32 	%f303, %f280;
	@%p11 bra 	$L__BB0_13;

	add.s32 	%r109, %r4, 1;
	mul.wide.u32 	%rd13, %r109, 4;
	add.s64 	%rd14, %rd1, %rd13;
	ld.global.f32 	%f161, [%rd14];
	mov.f32 	%f162, 0f00000000;
	fma.rn.f32 	%f304, %f161, 0f00000000, %f304;
	fma.rn.f32 	%f303, %f1, %f161, 0f00000000;
	mul.f32 	%f6, %f1, %f1;
	sub.f32 	%f280, %f162, %f6;
	mul.f32 	%f8, %f1, 0f00000000;
	add.f32 	%f281, %f8, %f8;
	abs.f32 	%f163, %f280;
	setp.le.f32 	%p12, %f163, 0f7F800000;
	@%p12 bra 	$L__BB0_12;

	abs.f32 	%f164, %f281;
	setp.le.f32 	%p13, %f164, 0f7F800000;
	@%p13 bra 	$L__BB0_12;

	abs.f32 	%f165, %f1;
	setp.neu.f32 	%p14, %f165, 0f7F800000;
	setp.eq.f32 	%p15, %f165, 0f7F800000;
	mov.f32 	%f166, 0f3F800000;
	copysign.f32 	%f10, %f1, %f166;
	selp.f32 	%f263, %f10, %f1, %p15;
	selp.u16 	%rs14, 1, 0, %p15;
	mov.f32 	%f264, %f1;
	@%p14 bra 	$L__BB0_6;

	abs.f32 	%f167, %f263;
	setp.le.f32 	%p16, %f167, 0f7F800000;
	mov.f32 	%f168, 0f00000000;
	copysign.f32 	%f169, %f263, %f168;
	selp.f32 	%f263, %f263, %f169, %p16;
	mov.u16 	%rs14, 1;
	mov.f32 	%f264, %f10;

$L__BB0_6:
	setp.ne.s16 	%p18, %rs14, 0;
	mov.pred 	%p17, 0;
	mov.pred 	%p180, %p17;
	@%p18 bra 	$L__BB0_10;

	abs.f32 	%f170, %f6;
	setp.eq.f32 	%p19, %f170, 0f7F800000;
	@%p19 bra 	$L__BB0_9;

	abs.f32 	%f171, %f8;
	setp.neu.f32 	%p21, %f171, 0f7F800000;
	mov.pred 	%p180, -1;
	@%p21 bra 	$L__BB0_10;

$L__BB0_9:
	abs.f32 	%f172, %f263;
	setp.le.f32 	%p23, %f172, 0f7F800000;
	mov.f32 	%f173, 0f00000000;
	copysign.f32 	%f174, %f263, %f173;
	selp.f32 	%f263, %f263, %f174, %p23;
	abs.f32 	%f175, %f264;
	setp.le.f32 	%p24, %f175, 0f7F800000;
	copysign.f32 	%f176, %f264, %f173;
	selp.f32 	%f264, %f264, %f176, %p24;
	mov.pred 	%p180, %p17;

$L__BB0_10:
	@%p180 bra 	$L__BB0_12;

	mul.f32 	%f177, %f263, %f264;
	mov.f32 	%f178, 0f00000000;
	sub.f32 	%f179, %f178, %f177;
	mul.f32 	%f280, %f179, 0f7F800000;
	mul.f32 	%f180, %f264, 0f00000000;
	fma.rn.f32 	%f181, %f263, 0f00000000, %f180;
	mul.f32 	%f281, %f181, 0f7F800000;

$L__BB0_12:
	add.s32 	%r241, %r4, 2;

$L__BB0_13:
	add.s32 	%r110, %r5, -2;
	setp.eq.s32 	%p25, %r110, %r4;
	@%p25 bra 	$L__BB0_43;

$L__BB0_14:
	mul.wide.u32 	%rd15, %r241, 4;
	add.s64 	%rd16, %rd1, %rd15;
	ld.global.f32 	%f182, [%rd16];
	fma.rn.f32 	%f33, %f280, %f182, %f304;
	fma.rn.f32 	%f34, %f281, %f182, %f303;
	mul.f32 	%f35, %f1, %f281;
	mul.f32 	%f36, %f280, 0f00000000;
	sub.f32 	%f291, %f36, %f35;
	mul.f32 	%f38, %f281, 0f00000000;
	mul.f32 	%f39, %f1, %f280;
	add.f32 	%f292, %f38, %f39;
	abs.f32 	%f183, %f291;
	setp.le.f32 	%p26, %f183, 0f7F800000;
	@%p26 bra 	$L__BB0_28;

	abs.f32 	%f184, %f292;
	setp.le.f32 	%p27, %f184, 0f7F800000;
	@%p27 bra 	$L__BB0_28;

	abs.f32 	%f41, %f280;
	setp.neu.f32 	%p28, %f41, 0f7F800000;
	abs.f32 	%f42, %f281;
	setp.neu.f32 	%p29, %f42, 0f7F800000;
	mov.u16 	%rs16, 0;
	and.pred  	%p30, %p28, %p29;
	mov.f32 	%f282, %f1;
	@%p30 bra 	$L__BB0_18;

	setp.eq.f32 	%p31, %f42, 0f7F800000;
	setp.eq.f32 	%p32, %f41, 0f7F800000;
	selp.f32 	%f185, 0f3F800000, 0f00000000, %p32;
	copysign.f32 	%f280, %f280, %f185;
	selp.f32 	%f186, 0f3F800000, 0f00000000, %p31;
	copysign.f32 	%f281, %f281, %f186;
	abs.f32 	%f187, %f1;
	setp.le.f32 	%p33, %f187, 0f7F800000;
	selp.f32 	%f282, %f1, %f3, %p33;
	mov.u16 	%rs16, 1;

$L__BB0_18:
	abs.f32 	%f188, %f282;
	setp.neu.f32 	%p34, %f188, 0f7F800000;
	@%p34 bra 	$L__BB0_20;

	mov.f32 	%f189, 0f3F800000;
	copysign.f32 	%f282, %f282, %f189;
	abs.f32 	%f190, %f280;
	setp.le.f32 	%p35, %f190, 0f7F800000;
	mov.f32 	%f191, 0f00000000;
	copysign.f32 	%f192, %f280, %f191;
	selp.f32 	%f280, %f280, %f192, %p35;
	abs.f32 	%f193, %f281;
	setp.le.f32 	%p36, %f193, 0f7F800000;
	copysign.f32 	%f194, %f281, %f191;
	selp.f32 	%f281, %f281, %f194, %p36;
	mov.u16 	%rs16, 1;

$L__BB0_20:
	setp.ne.s16 	%p38, %rs16, 0;
	mov.pred 	%p37, 0;
	mov.pred 	%p181, %p37;
	@%p38 bra 	$L__BB0_26;

	abs.f32 	%f195, %f36;
	setp.eq.f32 	%p39, %f195, 0f7F800000;
	@%p39 bra 	$L__BB0_25;

	abs.f32 	%f196, %f35;
	setp.eq.f32 	%p40, %f196, 0f7F800000;
	@%p40 bra 	$L__BB0_25;

	abs.f32 	%f197, %f39;
	setp.eq.f32 	%p41, %f197, 0f7F800000;
	@%p41 bra 	$L__BB0_25;

	abs.f32 	%f198, %f38;
	setp.neu.f32 	%p43, %f198, 0f7F800000;
	mov.pred 	%p181, -1;
	@%p43 bra 	$L__BB0_26;

$L__BB0_25:
	abs.f32 	%f199, %f280;
	setp.le.f32 	%p45, %f199, 0f7F800000;
	mov.f32 	%f200, 0f00000000;
	copysign.f32 	%f201, %f280, %f200;
	selp.f32 	%f280, %f280, %f201, %p45;
	abs.f32 	%f202, %f281;
	setp.le.f32 	%p46, %f202, 0f7F800000;
	copysign.f32 	%f203, %f281, %f200;
	selp.f32 	%f281, %f281, %f203, %p46;
	abs.f32 	%f204, %f282;
	setp.le.f32 	%p47, %f204, 0f7F800000;
	copysign.f32 	%f205, %f282, %f200;
	selp.f32 	%f282, %f282, %f205, %p47;
	mov.pred 	%p181, %p37;

$L__BB0_26:
	@%p181 bra 	$L__BB0_28;

	mul.f32 	%f206, %f280, 0f00000000;
	mul.f32 	%f207, %f281, %f282;
	sub.f32 	%f208, %f206, %f207;
	mul.f32 	%f291, %f208, 0f7F800000;
	mul.f32 	%f209, %f280, %f282;
	fma.rn.f32 	%f210, %f281, 0f00000000, %f209;
	mul.f32 	%f292, %f210, 0f7F800000;

$L__BB0_28:
	add.s32 	%r111, %r241, 1;
	mul.wide.u32 	%rd17, %r111, 4;
	add.s64 	%rd18, %rd1, %rd17;
	ld.global.f32 	%f211, [%rd18];
	fma.rn.f32 	%f304, %f291, %f211, %f33;
	fma.rn.f32 	%f303, %f292, %f211, %f34;
	mul.f32 	%f67, %f1, %f292;
	mul.f32 	%f68, %f291, 0f00000000;
	sub.f32 	%f280, %f68, %f67;
	mul.f32 	%f70, %f292, 0f00000000;
	mul.f32 	%f71, %f1, %f291;
	add.f32 	%f281, %f70, %f71;
	abs.f32 	%f212, %f280;
	setp.le.f32 	%p48, %f212, 0f7F800000;
	@%p48 bra 	$L__BB0_42;

	abs.f32 	%f213, %f281;
	setp.le.f32 	%p49, %f213, 0f7F800000;
	@%p49 bra 	$L__BB0_42;

	abs.f32 	%f73, %f291;
	setp.neu.f32 	%p50, %f73, 0f7F800000;
	abs.f32 	%f74, %f292;
	setp.neu.f32 	%p51, %f74, 0f7F800000;
	mov.u16 	%rs18, 0;
	and.pred  	%p52, %p50, %p51;
	mov.f32 	%f293, %f1;
	@%p52 bra 	$L__BB0_32;

	setp.eq.f32 	%p53, %f74, 0f7F800000;
	setp.eq.f32 	%p54, %f73, 0f7F800000;
	selp.f32 	%f214, 0f3F800000, 0f00000000, %p54;
	copysign.f32 	%f291, %f291, %f214;
	selp.f32 	%f215, 0f3F800000, 0f00000000, %p53;
	copysign.f32 	%f292, %f292, %f215;
	abs.f32 	%f216, %f1;
	setp.le.f32 	%p55, %f216, 0f7F800000;
	selp.f32 	%f293, %f1, %f3, %p55;
	mov.u16 	%rs18, 1;

$L__BB0_32:
	abs.f32 	%f217, %f293;
	setp.neu.f32 	%p56, %f217, 0f7F800000;
	@%p56 bra 	$L__BB0_34;

	mov.f32 	%f218, 0f3F800000;
	copysign.f32 	%f293, %f293, %f218;
	abs.f32 	%f219, %f291;
	setp.le.f32 	%p57, %f219, 0f7F800000;
	mov.f32 	%f220, 0f00000000;
	copysign.f32 	%f221, %f291, %f220;
	selp.f32 	%f291, %f291, %f221, %p57;
	abs.f32 	%f222, %f292;
	setp.le.f32 	%p58, %f222, 0f7F800000;
	copysign.f32 	%f223, %f292, %f220;
	selp.f32 	%f292, %f292, %f223, %p58;
	mov.u16 	%rs18, 1;

$L__BB0_34:
	setp.ne.s16 	%p60, %rs18, 0;
	mov.pred 	%p59, 0;
	mov.pred 	%p182, %p59;
	@%p60 bra 	$L__BB0_40;

	abs.f32 	%f224, %f68;
	setp.eq.f32 	%p61, %f224, 0f7F800000;
	@%p61 bra 	$L__BB0_39;

	abs.f32 	%f225, %f67;
	setp.eq.f32 	%p62, %f225, 0f7F800000;
	@%p62 bra 	$L__BB0_39;

	abs.f32 	%f226, %f71;
	setp.eq.f32 	%p63, %f226, 0f7F800000;
	@%p63 bra 	$L__BB0_39;

	abs.f32 	%f227, %f70;
	setp.neu.f32 	%p65, %f227, 0f7F800000;
	mov.pred 	%p182, -1;
	@%p65 bra 	$L__BB0_40;

$L__BB0_39:
	abs.f32 	%f228, %f291;
	setp.le.f32 	%p67, %f228, 0f7F800000;
	mov.f32 	%f229, 0f00000000;
	copysign.f32 	%f230, %f291, %f229;
	selp.f32 	%f291, %f291, %f230, %p67;
	abs.f32 	%f231, %f292;
	setp.le.f32 	%p68, %f231, 0f7F800000;
	copysign.f32 	%f232, %f292, %f229;
	selp.f32 	%f292, %f292, %f232, %p68;
	abs.f32 	%f233, %f293;
	setp.le.f32 	%p69, %f233, 0f7F800000;
	copysign.f32 	%f234, %f293, %f229;
	selp.f32 	%f293, %f293, %f234, %p69;
	mov.pred 	%p182, %p59;

$L__BB0_40:
	@%p182 bra 	$L__BB0_42;

	mul.f32 	%f235, %f291, 0f00000000;
	mul.f32 	%f236, %f292, %f293;
	sub.f32 	%f237, %f235, %f236;
	mul.f32 	%f280, %f237, 0f7F800000;
	mul.f32 	%f238, %f291, %f293;
	fma.rn.f32 	%f239, %f292, 0f00000000, %f238;
	mul.f32 	%f281, %f239, 0f7F800000;

$L__BB0_42:
	add.s32 	%r241, %r241, 2;
	setp.lt.u32 	%p70, %r241, %r5;
	@%p70 bra 	$L__BB0_14;

$L__BB0_43:
	sub.s32 	%r12, %r5, %r4;
	setp.lt.u32 	%p71, %r12, 2;
	@%p71 bra 	$L__BB0_110;

	add.s32 	%r13, %r3, -1;
	add.s32 	%r14, %r3, 1;
	mov.u32 	%r252, 1;
	not.b32 	%r113, %r4;
	add.s32 	%r15, %r5, %r113;
	add.s32 	%r114, %r5, -2;
	sub.s32 	%r115, %r114, %r4;
	and.b32  	%r255, %r15, 3;
	setp.lt.u32 	%p72, %r115, 3;
	@%p72 bra 	$L__BB0_95;

	sub.s32 	%r243, %r15, %r255;
	mov.u32 	%r252, 1;

$L__BB0_46:
	add.s32 	%r117, %r252, -1;
	setp.lt.u32 	%p73, %r6, %r117;
	setp.ge.u32 	%p74, %r6, %r12;
	or.pred  	%p75, %p74, %p73;
	@%p75 bra 	$L__BB0_58;

	// begin inline asm
	activemask.b32 %r118;
	// end inline asm
	setp.eq.s32 	%p76, %r6, %r117;
	@%p76 bra 	$L__BB0_53;
	bra.uni 	$L__BB0_48;

$L__BB0_53:
	setp.eq.s32 	%p81, %r2, 0;
	@%p81 bra 	$L__BB0_56;

	setp.eq.s32 	%p82, %r118, -1;
	mov.u32 	%r245, %r3;
	@%p82 bra 	$L__BB0_57;

	fns.b32 	%r245, %r118, 0, %r14;
	bra.uni 	$L__BB0_57;

$L__BB0_48:
	setp.eq.s32 	%p77, %r13, 0;
	@%p77 bra 	$L__BB0_51;

	setp.eq.s32 	%p78, %r118, -1;
	mov.u32 	%r244, %r13;
	@%p78 bra 	$L__BB0_52;

	fns.b32 	%r244, %r118, 0, %r3;
	bra.uni 	$L__BB0_52;

$L__BB0_56:
	brev.b32 	%r126, %r118;
	bfind.shiftamt.u32 	%r245, %r126;

$L__BB0_57:
	mov.b32 	%r127, %f304;
	mov.u32 	%r128, 31;
	shfl.sync.idx.b32 	%r129|%p83, %r127, %r245, %r128, %r118;
	mov.b32 	%r130, %f303;
	shfl.sync.idx.b32 	%r131|%p84, %r130, %r245, %r128, %r118;
	bra.uni 	$L__BB0_58;

$L__BB0_51:
	brev.b32 	%r120, %r118;
	bfind.shiftamt.u32 	%r244, %r120;

$L__BB0_52:
	mov.b32 	%r121, %f304;
	mov.u32 	%r122, 31;
	shfl.sync.idx.b32 	%r123|%p79, %r121, %r244, %r122, %r118;
	mov.b32 	%r124, %f303;
	shfl.sync.idx.b32 	%r125|%p80, %r124, %r244, %r122, %r118;
	mov.b32 	%f241, %r123;
	mov.b32 	%f242, %r125;
	sub.f32 	%f304, %f304, %f241;
	sub.f32 	%f303, %f303, %f242;

$L__BB0_58:
	setp.lt.u32 	%p85, %r6, %r252;
	or.pred  	%p87, %p74, %p85;
	@%p87 bra 	$L__BB0_70;

	// begin inline asm
	activemask.b32 %r132;
	// end inline asm
	setp.eq.s32 	%p88, %r6, %r252;
	@%p88 bra 	$L__BB0_65;
	bra.uni 	$L__BB0_60;

$L__BB0_65:
	setp.eq.s32 	%p93, %r2, 0;
	@%p93 bra 	$L__BB0_68;

	setp.eq.s32 	%p94, %r132, -1;
	mov.u32 	%r247, %r3;
	@%p94 bra 	$L__BB0_69;

	fns.b32 	%r247, %r132, 0, %r14;
	bra.uni 	$L__BB0_69;

$L__BB0_60:
	setp.eq.s32 	%p89, %r13, 0;
	@%p89 bra 	$L__BB0_63;

	setp.eq.s32 	%p90, %r132, -1;
	mov.u32 	%r246, %r13;
	@%p90 bra 	$L__BB0_64;

	fns.b32 	%r246, %r132, 0, %r3;
	bra.uni 	$L__BB0_64;

$L__BB0_68:
	brev.b32 	%r139, %r132;
	bfind.shiftamt.u32 	%r247, %r139;

$L__BB0_69:
	mov.b32 	%r140, %f304;
	mov.u32 	%r141, 31;
	shfl.sync.idx.b32 	%r142|%p95, %r140, %r247, %r141, %r132;
	mov.b32 	%r143, %f303;
	shfl.sync.idx.b32 	%r144|%p96, %r143, %r247, %r141, %r132;
	bra.uni 	$L__BB0_70;

$L__BB0_63:
	brev.b32 	%r133, %r132;
	bfind.shiftamt.u32 	%r246, %r133;

$L__BB0_64:
	mov.b32 	%r134, %f304;
	mov.u32 	%r135, 31;
	shfl.sync.idx.b32 	%r136|%p91, %r134, %r246, %r135, %r132;
	mov.b32 	%r137, %f303;
	shfl.sync.idx.b32 	%r138|%p92, %r137, %r246, %r135, %r132;
	mov.b32 	%f243, %r136;
	mov.b32 	%f244, %r138;
	sub.f32 	%f304, %f304, %f243;
	sub.f32 	%f303, %f303, %f244;

$L__BB0_70:
	add.s32 	%r34, %r252, 2;
	setp.le.u32 	%p97, %r6, %r252;
	or.pred  	%p99, %p74, %p97;
	@%p99 bra 	$L__BB0_82;

	// begin inline asm
	activemask.b32 %r145;
	// end inline asm
	add.s32 	%r146, %r252, 1;
	setp.eq.s32 	%p100, %r6, %r146;
	@%p100 bra 	$L__BB0_77;
	bra.uni 	$L__BB0_72;

$L__BB0_77:
	setp.eq.s32 	%p105, %r2, 0;
	@%p105 bra 	$L__BB0_80;

	setp.eq.s32 	%p106, %r145, -1;
	mov.u32 	%r249, %r3;
	@%p106 bra 	$L__BB0_81;

	fns.b32 	%r249, %r145, 0, %r14;
	bra.uni 	$L__BB0_81;

$L__BB0_72:
	setp.eq.s32 	%p101, %r13, 0;
	@%p101 bra 	$L__BB0_75;

	setp.eq.s32 	%p102, %r145, -1;
	mov.u32 	%r248, %r13;
	@%p102 bra 	$L__BB0_76;

	fns.b32 	%r248, %r145, 0, %r3;
	bra.uni 	$L__BB0_76;

$L__BB0_80:
	brev.b32 	%r153, %r145;
	bfind.shiftamt.u32 	%r249, %r153;

$L__BB0_81:
	mov.b32 	%r154, %f304;
	mov.u32 	%r155, 31;
	shfl.sync.idx.b32 	%r156|%p107, %r154, %r249, %r155, %r145;
	mov.b32 	%r157, %f303;
	shfl.sync.idx.b32 	%r158|%p108, %r157, %r249, %r155, %r145;
	bra.uni 	$L__BB0_82;

$L__BB0_75:
	brev.b32 	%r147, %r145;
	bfind.shiftamt.u32 	%r248, %r147;

$L__BB0_76:
	mov.b32 	%r148, %f304;
	mov.u32 	%r149, 31;
	shfl.sync.idx.b32 	%r150|%p103, %r148, %r248, %r149, %r145;
	mov.b32 	%r151, %f303;
	shfl.sync.idx.b32 	%r152|%p104, %r151, %r248, %r149, %r145;
	mov.b32 	%f245, %r150;
	mov.b32 	%f246, %r152;
	sub.f32 	%f304, %f304, %f245;
	sub.f32 	%f303, %f303, %f246;

$L__BB0_82:
	setp.lt.u32 	%p109, %r6, %r34;
	or.pred  	%p111, %p74, %p109;
	@%p111 bra 	$L__BB0_94;

	// begin inline asm
	activemask.b32 %r159;
	// end inline asm
	setp.eq.s32 	%p112, %r6, %r34;
	@%p112 bra 	$L__BB0_89;
	bra.uni 	$L__BB0_84;

$L__BB0_89:
	setp.eq.s32 	%p117, %r2, 0;
	@%p117 bra 	$L__BB0_92;

	setp.eq.s32 	%p118, %r159, -1;
	mov.u32 	%r251, %r3;
	@%p118 bra 	$L__BB0_93;

	fns.b32 	%r251, %r159, 0, %r14;
	bra.uni 	$L__BB0_93;

$L__BB0_84:
	setp.eq.s32 	%p113, %r13, 0;
	@%p113 bra 	$L__BB0_87;

	setp.eq.s32 	%p114, %r159, -1;
	mov.u32 	%r250, %r13;
	@%p114 bra 	$L__BB0_88;

	fns.b32 	%r250, %r159, 0, %r3;
	bra.uni 	$L__BB0_88;

$L__BB0_92:
	brev.b32 	%r166, %r159;
	bfind.shiftamt.u32 	%r251, %r166;

$L__BB0_93:
	mov.b32 	%r167, %f304;
	mov.u32 	%r168, 31;
	shfl.sync.idx.b32 	%r169|%p119, %r167, %r251, %r168, %r159;
	mov.b32 	%r170, %f303;
	shfl.sync.idx.b32 	%r171|%p120, %r170, %r251, %r168, %r159;
	bra.uni 	$L__BB0_94;

$L__BB0_87:
	brev.b32 	%r160, %r159;
	bfind.shiftamt.u32 	%r250, %r160;

$L__BB0_88:
	mov.b32 	%r161, %f304;
	mov.u32 	%r162, 31;
	shfl.sync.idx.b32 	%r163|%p115, %r161, %r250, %r162, %r159;
	mov.b32 	%r164, %f303;
	shfl.sync.idx.b32 	%r165|%p116, %r164, %r250, %r162, %r159;
	mov.b32 	%f247, %r163;
	mov.b32 	%f248, %r165;
	sub.f32 	%f304, %f304, %f247;
	sub.f32 	%f303, %f303, %f248;

$L__BB0_94:
	add.s32 	%r252, %r252, 4;
	add.s32 	%r243, %r243, -4;
	setp.ne.s32 	%p121, %r243, 0;
	@%p121 bra 	$L__BB0_46;

$L__BB0_95:
	setp.eq.s32 	%p122, %r255, 0;
	@%p122 bra 	$L__BB0_110;

	add.s32 	%r172, %r4, %r252;
	sub.s32 	%r254, %r172, %r3;
	add.s32 	%r253, %r252, -1;

$L__BB0_97:
	.pragma "nounroll";
	setp.lt.u32 	%p123, %r6, %r253;
	setp.ge.u32 	%p124, %r6, %r12;
	or.pred  	%p125, %p124, %p123;
	@%p125 bra 	$L__BB0_109;

	// begin inline asm
	activemask.b32 %r173;
	// end inline asm
	setp.eq.s32 	%p126, %r254, 1;
	@%p126 bra 	$L__BB0_104;
	bra.uni 	$L__BB0_99;

$L__BB0_104:
	setp.eq.s32 	%p131, %r2, 0;
	@%p131 bra 	$L__BB0_107;

	setp.eq.s32 	%p132, %r173, -1;
	mov.u32 	%r257, %r3;
	@%p132 bra 	$L__BB0_108;

	fns.b32 	%r257, %r173, 0, %r14;
	bra.uni 	$L__BB0_108;

$L__BB0_99:
	setp.eq.s32 	%p127, %r13, 0;
	@%p127 bra 	$L__BB0_102;

	setp.eq.s32 	%p128, %r173, -1;
	mov.u32 	%r256, %r13;
	@%p128 bra 	$L__BB0_103;

	fns.b32 	%r256, %r173, 0, %r3;
	bra.uni 	$L__BB0_103;

$L__BB0_107:
	brev.b32 	%r180, %r173;
	bfind.shiftamt.u32 	%r257, %r180;

$L__BB0_108:
	mov.b32 	%r181, %f304;
	mov.u32 	%r182, 31;
	shfl.sync.idx.b32 	%r183|%p133, %r181, %r257, %r182, %r173;
	mov.b32 	%r184, %f303;
	shfl.sync.idx.b32 	%r185|%p134, %r184, %r257, %r182, %r173;
	bra.uni 	$L__BB0_109;

$L__BB0_102:
	brev.b32 	%r174, %r173;
	bfind.shiftamt.u32 	%r256, %r174;

$L__BB0_103:
	mov.b32 	%r175, %f304;
	mov.u32 	%r176, 31;
	shfl.sync.idx.b32 	%r177|%p129, %r175, %r256, %r176, %r173;
	mov.b32 	%r178, %f303;
	shfl.sync.idx.b32 	%r179|%p130, %r178, %r256, %r176, %r173;
	mov.b32 	%f249, %r177;
	mov.b32 	%f250, %r179;
	sub.f32 	%f304, %f304, %f249;
	sub.f32 	%f303, %f303, %f250;

$L__BB0_109:
	add.s32 	%r254, %r254, 1;
	add.s32 	%r253, %r253, 1;
	add.s32 	%r255, %r255, -1;
	setp.ne.s32 	%p135, %r255, 0;
	@%p135 bra 	$L__BB0_97;

$L__BB0_110:
	setp.eq.s32 	%p136, %r101, 0;
	@%p136 bra 	$L__BB0_162;

	add.s32 	%r67, %r3, 1;
	brev.b32 	%r187, %r102;
	bfind.shiftamt.u32 	%r68, %r187;
	add.s32 	%r69, %r3, 2;
	and.b32  	%r269, %r101, 3;
	add.s32 	%r188, %r101, -1;
	setp.lt.u32 	%p137, %r188, 3;
	mov.u32 	%r268, 0;
	@%p137 bra 	$L__BB0_150;

	setp.eq.s32 	%p138, %r102, -1;
	sub.s32 	%r259, %r101, %r269;
	setp.eq.s32 	%p139, %r2, 0;
	mov.u32 	%r268, 0;
	or.pred  	%p4, %p139, %p138;
	selp.b32 	%r72, %r68, %r3, %p139;

$L__BB0_113:
	setp.eq.s32 	%p140, %r3, %r5;
	@%p140 bra 	$L__BB0_117;
	bra.uni 	$L__BB0_114;

$L__BB0_117:
	mov.u32 	%r261, %r72;
	@%p4 bra 	$L__BB0_119;

	fns.b32 	%r261, %r102, 0, %r67;

$L__BB0_119:
	mov.b32 	%r195, %f304;
	mov.u32 	%r196, 31;
	shfl.sync.idx.b32 	%r197|%p144, %r195, %r261, %r196, %r102;
	mov.b32 	%r198, %f303;
	shfl.sync.idx.b32 	%r199|%p145, %r198, %r261, %r196, %r102;
	bra.uni 	$L__BB0_120;

$L__BB0_114:
	mov.u32 	%r260, %r67;
	@%p138 bra 	$L__BB0_116;

	fns.b32 	%r260, %r102, 0, %r69;

$L__BB0_116:
	mov.b32 	%r190, %f304;
	mov.u32 	%r191, 31;
	shfl.sync.idx.b32 	%r192|%p142, %r190, %r260, %r191, %r102;
	mov.b32 	%r193, %f303;
	shfl.sync.idx.b32 	%r194|%p143, %r193, %r260, %r191, %r102;
	mov.b32 	%f251, %r192;
	mov.b32 	%f252, %r194;
	add.f32 	%f304, %f304, %f251;
	add.f32 	%f303, %f303, %f252;

$L__BB0_120:
	mul.wide.u32 	%rd19, %r268, 8;
	add.s64 	%rd3, %rd2, %rd19;
	setp.ne.s32 	%p146, %r6, 0;
	@%p146 bra 	$L__BB0_122;

	st.global.v2.f32 	[%rd3], {%f304, %f303};

$L__BB0_122:
	@%p140 bra 	$L__BB0_126;
	bra.uni 	$L__BB0_123;

$L__BB0_126:
	mov.u32 	%r263, %r72;
	@%p4 bra 	$L__BB0_128;

	fns.b32 	%r263, %r102, 0, %r67;

$L__BB0_128:
	mov.b32 	%r205, %f304;
	mov.u32 	%r206, 31;
	shfl.sync.idx.b32 	%r207|%p151, %r205, %r263, %r206, %r102;
	mov.b32 	%r208, %f303;
	shfl.sync.idx.b32 	%r209|%p152, %r208, %r263, %r206, %r102;
	bra.uni 	$L__BB0_129;

$L__BB0_123:
	mov.u32 	%r262, %r67;
	@%p138 bra 	$L__BB0_125;

	fns.b32 	%r262, %r102, 0, %r69;

$L__BB0_125:
	mov.b32 	%r200, %f304;
	mov.u32 	%r201, 31;
	shfl.sync.idx.b32 	%r202|%p149, %r200, %r262, %r201, %r102;
	mov.b32 	%r203, %f303;
	shfl.sync.idx.b32 	%r204|%p150, %r203, %r262, %r201, %r102;
	mov.b32 	%f253, %r202;
	mov.b32 	%f254, %r204;
	add.f32 	%f304, %f304, %f253;
	add.f32 	%f303, %f303, %f254;

$L__BB0_129:
	@%p146 bra 	$L__BB0_131;

	st.global.v2.f32 	[%rd3+8], {%f304, %f303};

$L__BB0_131:
	@%p140 bra 	$L__BB0_135;
	bra.uni 	$L__BB0_132;

$L__BB0_135:
	mov.u32 	%r265, %r72;
	@%p4 bra 	$L__BB0_137;

	fns.b32 	%r265, %r102, 0, %r67;

$L__BB0_137:
	mov.b32 	%r215, %f304;
	mov.u32 	%r216, 31;
	shfl.sync.idx.b32 	%r217|%p158, %r215, %r265, %r216, %r102;
	mov.b32 	%r218, %f303;
	shfl.sync.idx.b32 	%r219|%p159, %r218, %r265, %r216, %r102;
	bra.uni 	$L__BB0_138;

$L__BB0_132:
	mov.u32 	%r264, %r67;
	@%p138 bra 	$L__BB0_134;

	fns.b32 	%r264, %r102, 0, %r69;

$L__BB0_134:
	mov.b32 	%r210, %f304;
	mov.u32 	%r211, 31;
	shfl.sync.idx.b32 	%r212|%p156, %r210, %r264, %r211, %r102;
	mov.b32 	%r213, %f303;
	shfl.sync.idx.b32 	%r214|%p157, %r213, %r264, %r211, %r102;
	mov.b32 	%f255, %r212;
	mov.b32 	%f256, %r214;
	add.f32 	%f304, %f304, %f255;
	add.f32 	%f303, %f303, %f256;

$L__BB0_138:
	@%p146 bra 	$L__BB0_140;

	st.global.v2.f32 	[%rd3+16], {%f304, %f303};

$L__BB0_140:
	@%p140 bra 	$L__BB0_144;
	bra.uni 	$L__BB0_141;

$L__BB0_144:
	mov.u32 	%r267, %r72;
	@%p4 bra 	$L__BB0_146;

	fns.b32 	%r267, %r102, 0, %r67;

$L__BB0_146:
	mov.b32 	%r225, %f304;
	mov.u32 	%r226, 31;
	shfl.sync.idx.b32 	%r227|%p165, %r225, %r267, %r226, %r102;
	mov.b32 	%r228, %f303;
	shfl.sync.idx.b32 	%r229|%p166, %r228, %r267, %r226, %r102;
	bra.uni 	$L__BB0_147;

$L__BB0_141:
	mov.u32 	%r266, %r67;
	@%p138 bra 	$L__BB0_143;

	fns.b32 	%r266, %r102, 0, %r69;

$L__BB0_143:
	mov.b32 	%r220, %f304;
	mov.u32 	%r221, 31;
	shfl.sync.idx.b32 	%r222|%p163, %r220, %r266, %r221, %r102;
	mov.b32 	%r223, %f303;
	shfl.sync.idx.b32 	%r224|%p164, %r223, %r266, %r221, %r102;
	mov.b32 	%f257, %r222;
	mov.b32 	%f258, %r224;
	add.f32 	%f304, %f304, %f257;
	add.f32 	%f303, %f303, %f258;

$L__BB0_147:
	@%p146 bra 	$L__BB0_149;

	st.global.v2.f32 	[%rd3+24], {%f304, %f303};

$L__BB0_149:
	add.s32 	%r268, %r268, 4;
	add.s32 	%r259, %r259, -4;
	setp.ne.s32 	%p168, %r259, 0;
	@%p168 bra 	$L__BB0_113;

$L__BB0_150:
	setp.eq.s32 	%p169, %r269, 0;
	@%p169 bra 	$L__BB0_162;

	setp.eq.s32 	%p170, %r102, -1;
	setp.eq.s32 	%p171, %r2, 0;
	or.pred  	%p5, %p171, %p170;
	selp.b32 	%r94, %r68, %r3, %p171;
	mul.wide.u32 	%rd20, %r268, 8;
	add.s64 	%rd21, %rd2, %rd20;

$L__BB0_152:
	.pragma "nounroll";
	setp.eq.s32 	%p172, %r3, %r5;
	@%p172 bra 	$L__BB0_156;
	bra.uni 	$L__BB0_153;

$L__BB0_156:
	mov.u32 	%r271, %r94;
	@%p5 bra 	$L__BB0_158;

	fns.b32 	%r271, %r102, 0, %r67;

$L__BB0_158:
	mov.b32 	%r235, %f304;
	mov.u32 	%r236, 31;
	shfl.sync.idx.b32 	%r237|%p176, %r235, %r271, %r236, %r102;
	mov.b32 	%r238, %f303;
	shfl.sync.idx.b32 	%r239|%p177, %r238, %r271, %r236, %r102;
	bra.uni 	$L__BB0_159;

$L__BB0_153:
	mov.u32 	%r270, %r67;
	@%p170 bra 	$L__BB0_155;

	fns.b32 	%r270, %r102, 0, %r69;

$L__BB0_155:
	mov.b32 	%r230, %f304;
	mov.u32 	%r231, 31;
	shfl.sync.idx.b32 	%r232|%p174, %r230, %r270, %r231, %r102;
	mov.b32 	%r233, %f303;
	shfl.sync.idx.b32 	%r234|%p175, %r233, %r270, %r231, %r102;
	mov.b32 	%f259, %r232;
	mov.b32 	%f260, %r234;
	add.f32 	%f304, %f304, %f259;
	add.f32 	%f303, %f303, %f260;

$L__BB0_159:
	setp.ne.s32 	%p178, %r6, 0;
	@%p178 bra 	$L__BB0_161;

	st.global.v2.f32 	[%rd21], {%f304, %f303};

$L__BB0_161:
	add.s32 	%r269, %r269, -1;
	add.s64 	%rd21, %rd21, 8;
	setp.ne.s32 	%p179, %r269, 0;
	@%p179 bra 	$L__BB0_152;

$L__BB0_162:
	ret;

}
	// .globl	_ZN3cub17CUB_200802_SM_86011EmptyKernelIvEEvv
.visible .entry _ZN3cub17CUB_200802_SM_86011EmptyKernelIvEEvv()
{



	ret;

}

